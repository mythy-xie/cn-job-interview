# 1.1 概率与统计

## 1. 贝叶斯推断 (Bayesian Inference)

在高级算法视角下，模型参数 $\theta$ 不再是固定的标量，而是服从某种分布的**随机变量**。贝叶斯推断的核心在于通过观测数据 $D$ 更新对参数的信念：

$$P(\theta|D) = \frac{P(D|\theta)P(\theta)}{P(D)}$$

* **先验 (Prior) $P(\theta)$ 的正则化本质**：
    先验分布不仅仅是主观信念，在数学上等价于正则化项。例如，引入高斯先验 $\theta \sim \mathcal{N}(0, I)$ 等价于在 Loss 中加入 **L2 正则化 (Weight Decay)**；引入拉普拉斯先验则对应 **L1 正则化 (Sparsity)**。
* **不确定性量化 (Uncertainty Quantification)**：
    与点估计（Point Estimation）不同，贝叶斯推断产出的是分布。这对**大模型幻觉检测**（计算输出分布的熵）和**强化学习探索**（Thompson Sampling）至关重要。

## 2. 变分推断 (Variational Inference, VI)

由于贝叶斯公式中的分母 $P(D) = \int P(D|\theta)P(\theta) d\theta$ 涉及高维积分，解析解通常不可行（Intractable）。**VI** 的核心思想是将推断问题转化为**优化问题**。

* **优化目标**：
    寻找一个易于采样的分布族 $Q_\phi(z)$（如高斯分布），使其在 KL 散度意义上逼近真实后验 $P(z|x)$。
* **证据下界 (ELBO)**：
    最小化 KL 散度等价于最大化 ELBO。这是 **VAE (Variational Autoencoder)** 的数学基石：
    $$\log P(x) \ge \text{ELBO} = \mathbb{E}_{Q}[\log P(x|z)] - D_{KL}(Q(z)||P(z))$$
    * **第一项**：重构误差（Reconstruction Term），鼓励潜变量 $z$ 能还原数据。
    * **第二项**：正则项（Regularization Term），防止 $Q(z)$ 坍缩，迫使其接近先验分布。

## 3. 采样技术与蒙特卡洛方法 (MCMC & Sampling)

当分布过于复杂无法直接优化时，我们退而求其次进行采样近似。

* **重要性采样 (Importance Sampling)**：
    当无法从目标分布 $P(x)$ 采样时，引入建议分布 $Q(x)$ 进行加权。
    $$\mathbb{E}_{x \sim P}[f(x)] = \mathbb{E}_{x \sim Q}\left[ f(x) \frac{P(x)}{Q(x)} \right]$$
    * **面试考点**：在 **RLHF (PPO)** 算法中，由于策略网络 $\pi_\theta$ 在不断更新，我们需要使用旧策略 $\pi_{old}$ 产生的数据来更新新策略，此时 $\frac{\pi_\theta(a|s)}{\pi_{old}(a|s)}$ 即为重要性权重，用于修正分布偏移 (Distribution Shift)。
* **朗之万动力学 (Langevin Dynamics)**：
    利用梯度信息引导采样方向，加入高斯噪声以防止陷入局部最优。这是 **Diffusion Model (Score-based Generative Models)** 逆向生成过程的数学原型：
    $$x_{t+1} = x_t + \epsilon \nabla_x \log p(x) + \sqrt{2\epsilon} z_t$$

## 4. KL 散度与分布匹配 (KL Divergence)

KL 散度是衡量两个分布差异的非对称度量，其方向性决定了生成模型的行为特征。

* **前向 KL (Forward KL, $D_{KL}(P_{data}||P_{model})$)**：
    * **特性**：**Zero-forcing (Mean-Seeking)**。当真实数据 $P_{data}(x) > 0$ 时，模型必须分配概率。
    * **现象**：为了覆盖所有数据模式，模型倾向于在不同模态之间取平均，导致生成的图像模糊（Blurry）。这对应了 **MLE (极大似然估计)** 的训练目标。
* **反向 KL (Reverse KL, $D_{KL}(P_{model}||P_{data})$)**：
    * **特性**：**Zero-avoiding (Mode-Seeking)**。当真实数据 $P_{data}(x) = 0$ 时，模型必须为 0。
    * **现象**：模型倾向于坍缩到数据的某一个主要模态上（Mode Collapse），生成的样本清晰但缺乏多样性。这是 **GAN** 和 **VI** 训练中常见的问题。

## 5. 互信息 (Mutual Information, MI)

互信息衡量变量 $X$ 和 $Y$ 之间的非线性相关性：
$$I(X;Y) = H(X) - H(X|Y)$$

* **自监督学习 (Contrastive Learning)**：
    **InfoNCE Loss** 的本质是在最大化输入与正样本之间互信息的下界。通过拉近正样本对、推开负样本对，模型学到了能够最大程度保留原始数据信息的特征表示。
* **特征解耦 (Disentanglement)**：
    在理想的特征表示中，潜在变量 $z$ 的不同维度应当是独立的，即最小化维度间的互信息（Total Correlation），这在可解释性 AI 中尤为重要。